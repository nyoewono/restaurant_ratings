{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP30027_Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LgU2vbUfYyG2",
        "zYrbMA_Ebur2",
        "0eWAh_rgd1Oe",
        "IDjTDJmu6JCn",
        "C0yIq5mq6RHE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnyhn1h3NEiH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import scipy.sparse\n",
        "from sklearn.model_selection import cross_validate, GridSearchCV, cross_val_predict\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptho5KfY7Odo"
      },
      "source": [
        "# Analyse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDyBpWYLNrmg"
      },
      "source": [
        "meta_train = pd.read_csv(\"review_meta_train.csv\")\n",
        "meta_test = pd.read_csv(\"review_meta_test.csv\")\n",
        "text_train = pd.read_csv(\"review_text_train.csv\")\n",
        "text_test = pd.read_csv(\"review_text_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZQgvnCTytdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "8b85d201-6503-48c6-c0a0-1d7c3ec4aea3"
      },
      "source": [
        "label_dst = meta_train.groupby('rating').count().reset_index().loc[:, ['rating', 'date']]\n",
        "label_dst.columns = ['rating', 'distribution']\n",
        "label_dst['distribution'] = round((label_dst['distribution']/sum(label_dst['distribution']))*100, 2)\n",
        "label_dst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>distribution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>22.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>68.72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating  distribution\n",
              "0       1          8.32\n",
              "1       3         22.96\n",
              "2       5         68.72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gdy6aEo0FnM"
      },
      "source": [
        "From the table above, it can be seen that most of the text got 5 star rating. 1 star rating is the least one and 3 star is in the middle. Thus, they don't have an equal distribution, and this may effect the training process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0SM7kn2UXuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "af6391ea-cab3-4cb3-ce6f-44f8d5966296"
      },
      "source": [
        "print(\"Length of text training data:\", len(text_train['review']))\n",
        "print(\"Length of text test data: \", len(text_test['review']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text training data: 28068\n",
            "Length of text test data:  7018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyJggBhtaWcy"
      },
      "source": [
        "Extract data using CountVectorizer given"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxHCZzwXawF3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3229ff88-a35d-43f9-eec4-b5516ac899fb"
      },
      "source": [
        "count_vec_text_train = pickle.load(open(\"train_countvectorizer.pkl\", \"rb\"))\n",
        "vocab_text_train = count_vec_text_train.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKXElw2Zazqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88c3eea3-e032-47c7-f05e-d69f0f1bdb4d"
      },
      "source": [
        "print(\"There are \"+str(len(vocab_text_train))+\" distinct words in the training set\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 41648 distinct words in the training set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIyRgfshcA9I"
      },
      "source": [
        "Load the sparse matrix of the train text (becareful, the data might kill your RAM. Google Collab crash 2 times when load transform the object to an array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c0Gv7JghxgS"
      },
      "source": [
        "Load the doc2vec dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfrb5kAvgIFV"
      },
      "source": [
        "#train\n",
        "doc2vec_text_train50 = pd.read_csv(r\"review_text_train_doc2vec50.csv\", index_col = False, delimiter = ',', header=None) \n",
        "doc2vec_text_train100 = pd.read_csv(r\"review_text_train_doc2vec100.csv\", index_col = False, delimiter = ',', header=None) \n",
        "doc2vec_text_train200 = pd.read_csv(r\"review_text_train_doc2vec200.csv\", index_col = False, delimiter = ',', header=None) \n",
        "\n",
        "#test\n",
        "doc2vec_text_test50 = pd.read_csv(r\"review_text_test_doc2vec50.csv\", index_col = False, delimiter=',', header = None)\n",
        "doc2vec_text_test100 = pd.read_csv(r\"review_text_test_doc2vec100.csv\", index_col = False, delimiter = ',', header=None) \n",
        "doc2vec_text_test200 = pd.read_csv(r\"review_text_test_doc2vec200.csv\", index_col = False, delimiter = ',', header=None) \n",
        "\n",
        "\n",
        "# adding the extra features for train data \n",
        "doc2vec_text_train50_extra = doc2vec_text_train50.copy()\n",
        "doc2vec_text_train100_extra = doc2vec_text_train100.copy()\n",
        "doc2vec_text_train200_extra = doc2vec_text_train200.copy()\n",
        "frames = [doc2vec_text_train50_extra, meta_train.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "frames_1 = [doc2vec_text_train100_extra, meta_train.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "frames_2 = [doc2vec_text_train200_extra, meta_train.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "doc2vec_text_train50_extra = pd.concat(frames, axis=1)\n",
        "doc2vec_text_train100_extra = pd.concat(frames_1, axis=1)\n",
        "doc2vec_text_train200_extra = pd.concat(frames_2, axis=1)\n",
        "\n",
        "# adding the extra features for test data\n",
        "doc2vec_text_test50_extra = doc2vec_text_test50.copy()\n",
        "doc2vec_text_test100_extra = doc2vec_text_test100.copy()\n",
        "doc2vec_text_test200_extra = doc2vec_text_test200.copy()\n",
        "frames_test = [doc2vec_text_test50, meta_test.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "frames_test1 = [doc2vec_text_test100, meta_test.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "frames_test2 = [doc2vec_text_test200, meta_test.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]]\n",
        "doc2vec_text_test50_extra = pd.concat(frames_test, axis=1)\n",
        "doc2vec_text_test100_extra = pd.concat(frames_test1, axis=1)\n",
        "doc2vec_text_test200_extra = pd.concat(frames_test2, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2CtMJl57XAX"
      },
      "source": [
        "Get the original data count vec data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKkvntA87dJg"
      },
      "source": [
        "X_train = scipy.sparse.load_npz('review_text_train_vec.npz')\n",
        "y_train = meta_train['rating']\n",
        "X_test = scipy.sparse.load_npz('review_text_test_vec.npz')\n",
        "\n",
        "# get the additional features for the user vote, as this may help improve the classification accuracy\n",
        "extra_features = meta_train.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]\n",
        "extra_features_test = meta_test.loc[:, ['vote_funny', \"vote_cool\", \"vote_useful\"]]\n",
        "X_train_extra = scipy.sparse.hstack([X_train, extra_features]).tocsr()\n",
        "X_test_extra = scipy.sparse.hstack([X_test, extra_features_test]).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgU2vbUfYyG2"
      },
      "source": [
        "# Dimension Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYrbMA_Ebur2"
      },
      "source": [
        "#Chi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLYMDQp1bax2"
      },
      "source": [
        "x2 = SelectKBest(chi2, k=50)\n",
        "X_train_x2 = x2.fit_transform(X_train,y_train)\n",
        "X_test_x2 = x2.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A30VuDoc9WR"
      },
      "source": [
        "Show the top 50 relevant words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AemAKI6c8gT"
      },
      "source": [
        "top_50_words_x2 = []\n",
        "for feat_num in x2.get_support(indices=True):\n",
        "    top_50_words_x2.append(count_vec_text_train.get_feature_names()[feat_num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IVboYGmpVRD"
      },
      "source": [
        "X_train_x2_extra = scipy.sparse.hstack([X_train_x2, extra_features]).tocsr()\n",
        "x_test_x2_extra = scipy.sparse.hstack([X_test_x2, extra_features_test]).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eWAh_rgd1Oe"
      },
      "source": [
        "# Mutual Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKU9iuFd3iT"
      },
      "source": [
        "mi = SelectKBest(score_func=mutual_info_classif, k=50)\n",
        "X_train_mi = mi.fit_transform(X_train,y_train)\n",
        "X_test_mi = mi.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXZ5MxZ0kFXN"
      },
      "source": [
        "top_50_words_mui = []\n",
        "\n",
        "for feat_num in mi.get_support(indices=True):\n",
        "    top_50_words_mui.append(count_vec_text_train.get_feature_names()[feat_num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVyj4rd45Kxl"
      },
      "source": [
        "X_train_mi_extra = scipy.sparse.hstack([X_train_mi, extra_features]).tocsr()\n",
        "x_test_mi_extra = scipy.sparse.hstack([X_test_mi, extra_features_test]).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B45KHhBWdmBy"
      },
      "source": [
        "From the above 50 words, it can be seen that most of them are adj words, but some words like 'did didn wasn' are still included, and this may disturb the model valuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMB2vF0goFR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b3b4160-13e1-4abb-b943-80bf2b82f698"
      },
      "source": [
        "set(top_50_words_x2)-set(top_50_words_mui)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attitude', 'called', 'customers', 'hostess', 'poor', 'tasteless', 'waiter'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XPU1p-piDpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87a612e9-c9e9-45c2-a177-f0875ce313af"
      },
      "source": [
        "set(top_50_words_mui)-set(top_50_words_x2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'average', 'awesome', 'better', 'bit', 'fantastic', 'overpriced', 'think'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YtCHiRtvLho"
      },
      "source": [
        "It seems that from the top 50 words chosen, Chi manage to get more unique negative adj words in comparison to Mutual Information, and both have 7 different words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDjTDJmu6JCn"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0yIq5mq6RHE"
      },
      "source": [
        "# Baseline ONE R"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USHVAQQp6Wpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "609d9348-9ace-49bc-b83b-a94ea5a72768"
      },
      "source": [
        "data_train = [(doc2vec_text_train50, 'doc2vec50'), (X_train_x2, 'chi')]\n",
        "for X, title in data_train:\n",
        "\n",
        "  zero_r = DummyClassifier(strategy='most_frequent')\n",
        "  scores = cross_validate(zero_r, X, y_train, cv=10, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  clf_max = scores['estimator'][max_score]\n",
        "  benchmark_score = np.mean(scores['test_score'])\n",
        "  print(title)\n",
        "  print(\"Benchmark Score to beat: \"+str(benchmark_score))\n",
        "  print(\"Max score to beat: \"+str(scores['test_score'][max_score]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doc2vec50\n",
            "Benchmark Score to beat: 0.6871882761277236\n",
            "Max score to beat: 0.687455452601568\n",
            "chi\n",
            "Benchmark Score to beat: 0.6871882761277236\n",
            "Max score to beat: 0.687455452601568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp_zn8ICcOqz"
      },
      "source": [
        "#using any dataset will result in the same prediction\n",
        "prediction_0 = clf_max.predict(X_test_extra)\n",
        "instance_id = [i for i in range(1, len(prediction_0)+1)]\n",
        "df = pd.DataFrame([])\n",
        "df['Instance_id'] = instance_id\n",
        "df['rating'] = list(prediction_0)\n",
        "df.to_csv('test_zeroR_1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uq85pfm44dn"
      },
      "source": [
        "From using Zero R, we got 68.74% as the accuracy for all. Thus, this result will be used as the benchmark to test our various models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfWaBOKZ5Uar"
      },
      "source": [
        "# Rating Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scGLPSs35bTB"
      },
      "source": [
        "The model that is used in this first model would be Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAHfaNMB5PK1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4e834d00-e6cf-43aa-a95c-657b2f7f4ffd"
      },
      "source": [
        "data_train = [(doc2vec_text_train50, 'doc2vec50'), (doc2vec_text_train50_extra, 'doc2vec50_extra'), (X_train_x2, 'chi'), (X_train_x2_extra, 'chi_extra'), (X_train_mi, 'mi'), (X_train_mi_extra, 'mi_extra'), (X_train, 'original'), (X_train_extra, 'original_extra')]\n",
        "# set the class as multinomial NB\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# set the list to store informations\n",
        "clf_validate_max = []\n",
        "avg_score = []\n",
        "max_score_cv = []\n",
        "\n",
        "# Multinomial can't have negative number; thus, doc2vec will be excluded\n",
        "\n",
        "# iterate for every train data available using cross validation method\n",
        "for X, title in data_train[2:]:\n",
        "  scores = cross_validate(clf, X, y_train, cv=10, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  max_score_cv.append(scores['test_score'][max_score])\n",
        "  clf_validate_max.append(scores['estimator'][max_score])\n",
        "  avg_score.append(np.mean(scores['test_score']))\n",
        "  print(title)\n",
        "  print(\"avg accuracy: \"+str(round((np.mean(scores['test_score'])*100), 2)))\n",
        "  print(\"max accuracy: \"+str(round((scores['test_score'][max_score])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chi\n",
            "avg accuracy: 78.04\n",
            "max accuracy: 79.04\n",
            "chi_extra\n",
            "avg accuracy: 78.04\n",
            "max accuracy: 78.94\n",
            "mi\n",
            "avg accuracy: 78.88\n",
            "max accuracy: 79.84\n",
            "mi_extra\n",
            "avg accuracy: 78.73\n",
            "max accuracy: 79.65\n",
            "original\n",
            "avg accuracy: 83.9\n",
            "max accuracy: 84.72\n",
            "original_extra\n",
            "avg accuracy: 83.92\n",
            "max accuracy: 84.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ROXN-xSCmFB"
      },
      "source": [
        "Roughly, using cv of 10, it can be seen that original count vect data has the highest accuracy compared to the other; thus, to continue with the investigation, it is decided that count vector data with extra vote is used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1N6fd-JDOn9"
      },
      "source": [
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r2GfFhER6GB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e58d86e6-6f52-4282-b5c8-b0abe39decdd"
      },
      "source": [
        "parameter_candidates = [\n",
        "  {'alpha': [0.001, 0.01, 0.1, 1, 5, 10, 100]},\n",
        "]\n",
        "\n",
        "clf = GridSearchCV(estimator=MultinomialNB(), param_grid=parameter_candidates, n_jobs=-1)\n",
        "clf.fit(X_train_extra, y_train)\n",
        "\n",
        "print(\"Best accuracy: \"+str(clf.best_score_))\n",
        "print(\"Best alpha: \"+str(clf.best_estimator_.alpha))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.8384280321313741\n",
            "Best alpha: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v1Yp0mjrPVG"
      },
      "source": [
        "Since the best parameter is alpha=1, which is the default value, the investigation is over for MNB; thus, first model chosen to predict the rating is MNB with alpha=1, using the count vector data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nubej8CWUT2q"
      },
      "source": [
        "###Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Wu4pwENFLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "98750d74-982b-4388-bead-132f005f59df"
      },
      "source": [
        "hold = [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "clf = MultinomialNB()\n",
        "clf_validate_max = []\n",
        "avg_score = []\n",
        "max_score_cv = []\n",
        "for each_hold in hold:\n",
        "  scores = cross_validate(clf, X_train_extra, y_train, cv=each_hold, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  max_score_cv.append(scores['test_score'][max_score])\n",
        "  clf_validate_max.append(scores['estimator'][max_score])\n",
        "  avg_score.append(np.mean(scores['test_score']))\n",
        "  print('MNB '+str(each_hold)+\" cv\")\n",
        "  print(\"avg accuracy: \"+str(round((np.mean(scores['test_score'])*100), 2)))\n",
        "  print(\"max accuracy: \"+str(round((scores['test_score'][max_score])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNB 3 cv\n",
            "avg accuracy: 83.55\n",
            "max accuracy: 83.65\n",
            "MNB 4 cv\n",
            "avg accuracy: 83.69\n",
            "max accuracy: 83.88\n",
            "MNB 5 cv\n",
            "avg accuracy: 83.84\n",
            "max accuracy: 84.25\n",
            "MNB 6 cv\n",
            "avg accuracy: 83.88\n",
            "max accuracy: 84.31\n",
            "MNB 7 cv\n",
            "avg accuracy: 83.95\n",
            "max accuracy: 85.08\n",
            "MNB 8 cv\n",
            "avg accuracy: 83.92\n",
            "max accuracy: 84.75\n",
            "MNB 9 cv\n",
            "avg accuracy: 84.01\n",
            "max accuracy: 84.58\n",
            "MNB 10 cv\n",
            "avg accuracy: 83.92\n",
            "max accuracy: 84.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fZ2E_D43rr4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "aa035dd1-2125-4361-9386-b53f9b6c8bee"
      },
      "source": [
        "plt.plot(hold,avg_score)\n",
        "plt.xlabel('hold')\n",
        "plt.ylabel('accuracy')\n",
        "plt.suptitle('Multinomial NB Average Accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0.98, 'Multinomial NB Average Accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP7HWpWUoevR"
      },
      "source": [
        "Calculate the predict proba using the fitted classifer for stack input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxYzFzAcodsC"
      },
      "source": [
        "MNB_max = clf_validate_max[6]\n",
        "y_pred_mnb_proba = pd.DataFrame(MNB_max.predict_proba(X_test_extra))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcwhATh3pVai"
      },
      "source": [
        "Calculate the evaluation metrics: time and classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7t7ZdEBM_Tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ec6e892-4070-4b4e-ce16-32b9f7bda006"
      },
      "source": [
        "start = time.time()\n",
        "scores = cross_validate(clf, X_train_extra, y_train, cv=10, return_estimator=True)\n",
        "end = time.time()\n",
        "print(\"Total time: \", str(end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time:  0.2959418296813965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OlqHHegMs5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2dd1fe0c-f3b7-4c45-d3c5-ead3c4cd20f0"
      },
      "source": [
        "y_pred = cross_val_predict(clf, X_train_extra, y_train, cv=9)\n",
        "print(classification_report(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.74      0.60      0.66      2336\n",
            "           3       0.69      0.64      0.67      6444\n",
            "           5       0.89      0.94      0.91     19288\n",
            "\n",
            "    accuracy                           0.84     28068\n",
            "   macro avg       0.78      0.73      0.75     28068\n",
            "weighted avg       0.83      0.84      0.84     28068\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS3-2vtYVWE-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d699a38f-77e7-4606-a32d-795ed4f86705"
      },
      "source": [
        "print(confusion_matrix(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1398   748   190]\n",
            " [  328  4143  1973]\n",
            " [  159  1091 18038]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FroWcClNNLS"
      },
      "source": [
        "Turns out that without doing feature selection, MNB is very fast in learning all of the features, and it also increases its accuracy. Thus, it is decided that the final model would be to train the model using all of the features with MNB, and do a CV of 9 fold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ7QaDJPVkzQ"
      },
      "source": [
        "#### Prediction for the test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreTLc3RM7QQ"
      },
      "source": [
        "prediction_1 = MNB_max.predict(X_test_extra)\n",
        "instance_id = [i for i in range(1, len(prediction_1)+1)]\n",
        "df = pd.DataFrame([])\n",
        "df['Instance_id'] = instance_id\n",
        "df['rating'] = list(prediction_1)\n",
        "df.to_csv('test_MNB_8.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfAEGqYzdiqS"
      },
      "source": [
        "# Rating Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g3ueExXdp6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "0f9f4454-adb6-40f2-bf56-ef5e5bfc5113"
      },
      "source": [
        "clf = LogisticRegression()\n",
        "\n",
        "# already test on the rest of the data, but cell got deleted. Here is the most essential data\n",
        "data_train = [(doc2vec_text_train200, 'doc2vec200'), (doc2vec_text_train200_extra, 'doc2vec200_extra'),\n",
        "              (X_train, 'original'), (X_train_extra, 'original_extra')]\n",
        "\n",
        "# set the list to store informations\n",
        "clf_validate_max = []\n",
        "avg_score = []\n",
        "max_score_cv = []\n",
        "\n",
        "# iterate for every train data available using cross validation method\n",
        "for X, title in data_train:\n",
        "  scores = cross_validate(clf, X, y_train, cv=10, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  max_score_cv.append(scores['test_score'][max_score])\n",
        "  clf_validate_max.append(scores['estimator'][max_score])\n",
        "  avg_score.append(np.mean(scores['test_score']))\n",
        "  print(title)\n",
        "  print(\"avg accuracy: \"+str(round((np.mean(scores['test_score'])*100), 2)))\n",
        "  print(\"max accuracy: \"+str(round((scores['test_score'][max_score])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doc2vec50\n",
            "avg accuracy: 81.69\n",
            "max accuracy: 83.07\n",
            "doc2vec50_extra\n",
            "avg accuracy: 82.21\n",
            "max accuracy: 83.68\n",
            "doc2vec100\n",
            "avg accuracy: 82.59\n",
            "max accuracy: 83.5\n",
            "doc2vec100_extra\n",
            "avg accuracy: 83.02\n",
            "max accuracy: 83.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-5d3d758a72d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# iterate for every train data available using cross validation method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mmax_score_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20353, 28068]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0omECaygC7H"
      },
      "source": [
        "In logistic regression, the count vector original with extra user votes works better than the doc2vec, but still decided to investigate both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDrryo_dsZWH"
      },
      "source": [
        "##Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unVoqZ9vrRnL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "978efd52-6357-4a79-fa64-bf0c65ae5d8d"
      },
      "source": [
        "parameter_candidates = [\n",
        "  {'C': [1, 10, 100], 'max_iter':[100, 1000, 10000], 'dual':[True, False], 'solver':['saga', 'sag'], 'multi_class':['multinomial']},\n",
        "]\n",
        "\n",
        "clf = GridSearchCV(estimator=LogisticRegression(), param_grid=parameter_candidates, n_jobs=-1)\n",
        "clf.fit(doc2vec_text_train200_extra, y_train)\n",
        "\n",
        "print(\"Best accuracy: \"+str(clf.best_score_))\n",
        "print(\"Best C: \"+str(clf.best_estimator_.C))\n",
        "print(\"Best max_iter: \"+str(clf.best_estimator_.max_iter))\n",
        "print(\"Best dual: \"+str(clf.best_estimator_.dual))\n",
        "print(\"Best solver: \"+str(clf.best_estimator_.solver))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best accuracy: 0.8355065099969273\n",
            "Best C: 10\n",
            "Best max_iter: 100\n",
            "Best dual: False\n",
            "Best solver: saga\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoOwMrw51yL7"
      },
      "source": [
        "## Performance Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWZp6wrKryx6"
      },
      "source": [
        "Testing on the doc2vec data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkzPmW7t11Pt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "7c4bdb77-a3ad-469c-ab78-b914371d5cb4"
      },
      "source": [
        "hold = [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "clf = LogisticRegression(C=10, max_iter=1000, solver='saga', multi_class='multinomial')\n",
        "clf_validate_max = []\n",
        "avg_score = []\n",
        "max_score_cv = []\n",
        "for each_hold in hold:\n",
        "  scores = cross_validate(clf, doc2vec_text_train200_extra, y_train, cv=each_hold, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  max_score_cv.append(scores['test_score'][max_score])\n",
        "  clf_validate_max.append(scores['estimator'][max_score])\n",
        "  avg_score.append(np.mean(scores['test_score']))\n",
        "  print('Logistic Regression '+str(each_hold)+\" cv\")\n",
        "  print(\"avg accuracy: \"+str(round((np.mean(scores['test_score'])*100), 2)))\n",
        "  print(\"max accuracy: \"+str(round((scores['test_score'][max_score])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-242b79fee64c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_score_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach_hold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc2vec_text_train200_extra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meach_hold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmax_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmax_score_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    975\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                 is_saga=(solver == 'saga'))\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    324\u001b[0m                             \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                             \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                             verbose)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVec3zliJpyi"
      },
      "source": [
        "plt.plot(hold,avg_score)\n",
        "plt.xlabel('fold')\n",
        "plt.ylabel('accuracy')\n",
        "plt.suptitle('Logistic Regression Average Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEnp_TRwtMJl"
      },
      "source": [
        "Get the predict proba for stack input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELeKFpvotEmB"
      },
      "source": [
        "lr_2_max = score['estimator'][np.argmax(score['test_score'])]\n",
        "y_pred_lr_2_proba = pd.DataFrame(lr_2_max.predict_proba(doc2vec_text_test200_extra))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkd6XXgksFZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "57930a97-203c-4879-c52b-5fbc7b64c86c"
      },
      "source": [
        "clf = LogisticRegression(C=10, max_iter=1000, solver='saga', multi_class='multinomial')\n",
        "start = time.time()\n",
        "y_pred = cross_val_predict(clf, doc2vec_text_train200_extra, y_train, cv=6)\n",
        "end = time.time()\n",
        "print(classification_report(y_train, y_pred))\n",
        "print(\"Time:\", str(end-start))\n",
        "print(confusion_matrix(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.60      0.66      2336\n",
            "           3       0.72      0.61      0.66      6444\n",
            "           5       0.88      0.94      0.91     19288\n",
            "\n",
            "    accuracy                           0.84     28068\n",
            "   macro avg       0.78      0.72      0.74     28068\n",
            "weighted avg       0.83      0.84      0.83     28068\n",
            "\n",
            "Time: 173.35380625724792\n",
            "[[ 1394   537   405]\n",
            " [  380  3931  2133]\n",
            " [  135  1009 18144]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKtH4ZU-r3bb"
      },
      "source": [
        "Testing on the count vector with extra user vote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSAWgDZU7ph7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ca740c5-cc03-4024-be99-c008d9d6b838"
      },
      "source": [
        "hold = [3, 4, 5, 6, 7, 8, 9, 10]\n",
        "clf = LogisticRegression(C=10, max_iter=2000, solver='saga', multi_class='multinomial')\n",
        "clf_validate_max = []\n",
        "avg_score = []\n",
        "max_score_cv = []\n",
        "for each_hold in hold:\n",
        "  scores = cross_validate(clf, X_train_extra, y_train, cv=each_hold, return_estimator=True)\n",
        "  max_score = np.argmax(scores['test_score'])\n",
        "  max_score_cv.append(scores['test_score'][max_score])\n",
        "  clf_validate_max.append(scores['estimator'][max_score])\n",
        "  avg_score.append(np.mean(scores['test_score']))\n",
        "  print('Logistic Regression '+str(each_hold)+\" cv\")\n",
        "  print(\"avg accuracy: \"+str(round((np.mean(scores['test_score'])*100), 2)))\n",
        "  print(\"max accuracy: \"+str(round((scores['test_score'][max_score])*100, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 3 cv\n",
            "avg accuracy: 84.72\n",
            "max accuracy: 85.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 4 cv\n",
            "avg accuracy: 85.01\n",
            "max accuracy: 85.68\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 5 cv\n",
            "avg accuracy: 84.98\n",
            "max accuracy: 85.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 6 cv\n",
            "avg accuracy: 85.1\n",
            "max accuracy: 85.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 7 cv\n",
            "avg accuracy: 85.22\n",
            "max accuracy: 85.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 8 cv\n",
            "avg accuracy: 85.23\n",
            "max accuracy: 86.09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 9 cv\n",
            "avg accuracy: 85.09\n",
            "max accuracy: 86.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression 10 cv\n",
            "avg accuracy: 85.25\n",
            "max accuracy: 86.39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF_razid081d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "da2df78f-fad4-42b2-f04f-9b8d916fdd87"
      },
      "source": [
        "clf = LogisticRegression(C=10, max_iter=2000, solver='saga', multi_class='multinomial')\n",
        "start = time.time()\n",
        "y_pred = cross_val_predict(clf, X_train_extra, y_train, cv=10)\n",
        "end = time.time()\n",
        "print(classification_report(y_train, y_pred))\n",
        "print(\"Time:\", str(end-start))\n",
        "print(confusion_matrix(y_train, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.78      0.70      0.74      2336\n",
            "           3       0.73      0.65      0.69      6444\n",
            "           5       0.90      0.94      0.92     19288\n",
            "\n",
            "    accuracy                           0.85     28068\n",
            "   macro avg       0.80      0.76      0.78     28068\n",
            "weighted avg       0.85      0.85      0.85     28068\n",
            "\n",
            "Time: 969.6266918182373\n",
            "[[ 1640   490   206]\n",
            " [  365  4218  1861]\n",
            " [  110  1109 18069]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtaJ2UM-Lr_f"
      },
      "source": [
        "From the logistic regression, it is decided to use the count vector with extra user vote to represent the fit classifier; however, since the doc2vec result has its own forte, it is decided that it will be included in the stack for extra backup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mp-JHdqtR2l"
      },
      "source": [
        "Get the predict proba for stack input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qDQDIO0svg5"
      },
      "source": [
        "lr_1_max = clf_validate_max[-1]\n",
        "y_pred_lr_1_proba = pd.DataFrame(lr_1_max.predict_proba(X_test_extra))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd4UiCCSrf6W"
      },
      "source": [
        "#clf = LogisticRegression(C=10, max_iter=1000, solver='saga', multi_class='multinomial')\n",
        "#scores = cross_validate(clf, X_train_extra, y_train, cv=10, return_estimator=True)\n",
        "prediction_3 = clf_validate_max[-1].predict(X_test_extra)\n",
        "instance_id = [i for i in range(1, len(prediction_3)+1)]\n",
        "df = pd.DataFrame([])\n",
        "df['Instance_id'] = instance_id\n",
        "df['rating'] = list(prediction_3)\n",
        "df.to_csv('test_logistic_4.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2oqLQjc7asr"
      },
      "source": [
        "# Rating Model 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG7klRH7-J3F"
      },
      "source": [
        "### Implement Stack for MNB and Logistic Regression using DT as meta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UX68Ebft5yP"
      },
      "source": [
        "Use predict proba for each train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI2NkGPLsGQi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "af673c54-8caa-4bb5-9a55-32d87a66b442"
      },
      "source": [
        "start = time.time()\n",
        "# prediction from MNB\n",
        "mnb = MultinomialNB(alpha=1)\n",
        "y_pred_mnb = cross_val_predict(mnb, X_train_extra, y_train, cv=7, method='predict_proba')\n",
        "y_pred_mnb = pd.DataFrame(y_pred_mnb)\n",
        "\n",
        "# prediction from Logistic Regression\n",
        "lr_1 = LogisticRegression(C=10, max_iter=2000, solver='saga', multi_class='multinomial')\n",
        "y_pred_lr_1 = cross_val_predict(lr_1, X_train_extra, y_train, cv=10, method='predict_proba')\n",
        "y_pred_lr_1 = pd.DataFrame(y_pred_lr_1)\n",
        "\n",
        "# prediction from Logistic Regression\n",
        "lr_2 = LogisticRegression(C=10, max_iter=1000, solver='saga', multi_class='multinomial')\n",
        "y_pred_lr_2 = cross_val_predict(lr_2, doc2vec_text_train200_extra, y_train, cv=6, method='predict_proba')\n",
        "y_pred_lr_2 = pd.DataFrame(y_pred_lr_2)\n",
        "\n",
        "end = time.time()\n",
        "print('time:', str(end-start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "time: 1206.2880592346191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoK-kPVfuAfo"
      },
      "source": [
        "Set the predict train proba to test the classifier acc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaUZ9s28Hy1f"
      },
      "source": [
        "meta_input = pd.DataFrame([])\n",
        "model = [y_pred_mnb, y_pred_lr_1, y_pred_lr_2]\n",
        "counter=0\n",
        "for model_proba in model:\n",
        "  for i in range(3):\n",
        "    meta_input[counter] = model_proba[i]\n",
        "    counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h1sPcxfuKI1"
      },
      "source": [
        "Do the stack train testing to get the best classifier using logistic regression as the meta classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPXuvwGbEnLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9243305f-73ed-4363-f28a-2b94e8ad420e"
      },
      "source": [
        "meta = LogisticRegression()\n",
        "score = cross_validate(meta, meta_input, y_train, cv=10, return_estimator=True)\n",
        "print(score['test_score'])\n",
        "print(np.mean(score['test_score']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.86034913 0.8717492  0.87887424 0.85749911 0.86854293 0.87495547\n",
            " 0.87210545 0.86034913 0.87990021 0.87918746]\n",
            "0.8703512321934193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX_TBOR_LmGe"
      },
      "source": [
        "meta_max = score['estimator'][np.argmax(score['test_score'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N858FHcVH1Rf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8392602b-d593-44af-85d2-460b2929f152"
      },
      "source": [
        "start = time.time()\n",
        "y_meta = cross_val_predict(meta_max, meta_input, y_train, cv=10)\n",
        "end = time.time()\n",
        "print(classification_report(y_train, y_meta))\n",
        "print('time: '+str(end-start))\n",
        "print(confusion_matrix(y_train, y_meta))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.71      0.76      2336\n",
            "           3       0.76      0.68      0.72      6444\n",
            "           5       0.91      0.95      0.93     19288\n",
            "\n",
            "    accuracy                           0.87     28068\n",
            "   macro avg       0.83      0.78      0.80     28068\n",
            "weighted avg       0.87      0.87      0.87     28068\n",
            "\n",
            "time: 7.366491317749023\n",
            "[[ 1654   511   171]\n",
            " [  283  4407  1754]\n",
            " [   61   859 18368]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Ixo2swO64d"
      },
      "source": [
        "## Proba test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkygDnUQOLGJ"
      },
      "source": [
        "meta_input_test = pd.DataFrame([])\n",
        "model_test = [y_pred_mnb_proba, y_pred_lr_1_proba, y_pred_lr_2_proba]\n",
        "counter=0\n",
        "\n",
        "for model_proba in model_test:\n",
        "  for i in range(3):\n",
        "    meta_input_test[counter] = model_proba[i]\n",
        "    counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t_kszUHXwiX"
      },
      "source": [
        "meta_prediction = meta_max.predict(meta_input_test)\n",
        "df = pd.DataFrame([])\n",
        "df['Instance_id'] = [i for i in range(1, len(meta_prediction)+1)]\n",
        "df['rating'] = list(meta_prediction)\n",
        "df.to_csv('test_stack_8.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}